---
title: "Data_cleaning"
author: "Bobby Drysdale"
date: "11/20/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(janitor)
library(fs)
library(stringr)

#Downloading Upshot data

download.file(url = "https://goo.gl/ZRCBda", destfile = "master.zip", quiet = TRUE, mode = "wb")

unzip("master.zip")

# Removing zip file to unclutter folder

file_delete("master.zip")

#Read in and explore the election context data provided 

context <- read_csv("https://raw.githubusercontent.com/MEDSL/2018-elections/master/election-context-2018.csv")
```

```{r}
#Reading in all csv poll files into one dataframe

allfiles <- dir_ls("2018-live-poll-results-master/data")
rawmaster <- map_dfr(allfiles, read_csv, .id = "source")

#Adding identifying variables to dataset to make it easier to identify district and state
rawmaster <- rawmaster %>% 
mutate(state = toupper(str_sub(source, 51, 52))) %>% mutate(district = toupper(str_sub(source, 51, 54))) %>% mutate(wave = toupper(str_sub(source, 51, 56)))

#First I create will play with the predicted datsets

#I make two seperate datasets to get the latest polls from the duplicate districts and combine them with the non duplicated ones

nodups <- rawmaster %>% 
  group_by(wave) %>% 
  select(wave, district, state, response, final_weight) %>% 
  mutate(total = sum(final_weight)) %>% 
  filter(response %in% c("Dem", "Rep", "Und")) %>%
  group_by(wave, district, state, response, total) %>% tally(wt = final_weight) %>%
  spread(key = response, value = n) %>% group_by(district) %>% filter(n() == 1)
  
dup <- rawmaster %>% 
  group_by(wave) %>% 
  select(wave, district, state, response, final_weight) %>% 
  mutate(total = sum(final_weight)) %>%  
  filter(response %in% c("Dem", "Rep", "Und")) %>% 
  group_by(wave, district, state, response, total) %>% tally(wt = final_weight) %>% 
  spread(key = response, value = n) %>% group_by(district) %>% filter(n() > 1) %>% mutate(Poll = toupper(str_sub(wave, 6))) %>% mutate(Poll = fct_recode(Poll, 
                           "Poll 1" = "1",
                           "Poll 1" = 
"2",
                           "Poll 2" = "3")) %>% filter(Poll == "Poll 2") %>% select(-Poll)

#Once these two datasets are made, I combine them into one 

premaster <- rbind(dup, nodups) %>% 
  ungroup(district) %>%
  
#I will be looking at only House Data, therefore I will next filter out the Senate and Government Observations
  
  filter(!str_detect(district, "SE")) %>% filter(!str_detect(district, "GO")) %>% 
  
#Now I calculate the Republican advantage
  
mutate(rep_adv = (Rep - Dem) / total)

# I am now bringing in the actual results
mt_2_results <- read_csv("mt_2_results.csv")

#Creating the same republican advantage variable but naming it act_adv to show distinction from the predicted 

mt_2_results <- mt_2_results %>% 
  mutate(district = paste(state, district, sep = "")) %>% mutate(act_adv = (rep_votes - dem_votes)/(rep_votes + dem_votes + other_votes)) %>% select(district, act_adv)

#Now I am joining the predicted and actual datasets together

combined_master <- left_join(premaster, mt_2_results)

#creating the error beteen the actual and predicted advantages

combined_master <- combined_master %>% 
  mutate(error = abs(rep_adv - act_adv)) %>% select(state, district, rep_adv, act_adv, error)
```

```{r}
#Now I bring in the context data that is linked in the Problem set

contextdata <- read_csv("election-context-2018.csv")

#Looking at the available variables, I decide to look at both education and household variables

contextdata <- contextdata %>% 
  select(state,median_hh_inc, clf_unemploy_pct, lesshs_pct, lesscollege_pct, lesshs_whites_pct, lesscollege_whites_pct, rural_pct) %>% 
  drop_na() %>% 
  #since there is no districts explictly given, I do I similar switch as Ms. Gayton and do only states
  group_by(state) %>% 
  summarise(
    median_hh_inc = sum(median_hh_inc),
    clf_unemploy_pct = mean(clf_unemploy_pct),
    lesshs_pct = mean(lesshs_pct),
    lesscollege_pct = mean(lesscollege_pct),
    lesshs_whites_pct = mean(lesshs_whites_pct),
    lesscollege_whites_pct = mean(lesscollege_whites_pct),
    rural_pct = mean(rural_pct))

#This function I used from Mr.Gayton to change the state names to abbreviations in order to merge with my other dataset

to_abb <- function(x) {
  i <- 1
  for(i in 1:length(state.name)) {
    if(x == state.name[i]) {
      x <- state.abb[i]
      break
    }
    i + 1
  }
  return(x)
}

contextdata$state <- lapply(contextdata$state, to_abb)

contextdata <- contextdata %>% 
  mutate(state = as.character(state))

#Merging with my other dataset
master_context <- left_join(combined_master, contextdata, by = "state") %>% 
  
  #Making sure all variables are summarized by state
  
  group_by(state) %>% 
  summarise(
    rep_adv = mean(rep_adv),
    act_adv = mean(act_adv), 
    error = mean(error),median_hh_inc = sum(median_hh_inc),
    clf_unemploy_pct = mean(clf_unemploy_pct),
    lesshs_pct = mean(lesshs_pct),
    lesscollege_pct = mean(lesscollege_pct),
    lesshs_whites_pct = mean(lesshs_whites_pct),
    lesscollege_whites_pct = mean(lesscollege_whites_pct),
    rural_pct = mean(rural_pct)
  )

#Writing RDS file for use in shiny app
write_rds(master_context,"ps_7/master_context.rds")
```

